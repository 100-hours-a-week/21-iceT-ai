<<<<<<< HEAD
from src.adapters.vllm import generate
from src.schemas.solution_schema import SolutionRequest, SolutionResponse
from src.core.prompt_templates import SOLUTION_PROMPT
=======
from src.core.prompt_templates import SOLUTION_PROMPT
from src.adapters.llm_client import generate_solution
from src.schemas.solution_schema import SolutionRequest, SolutionResponse
>>>>>>> origin/dev

# ë¬¸ì œ ìš”ì²­ì„ ê¸°ë°˜ìœ¼ë¡œ í•´ì„¤ ìƒì„±í•˜ëŠ” ì„œë¹„ìŠ¤ í•¨ìˆ˜
async def explain_solution(req: SolutionRequest) -> SolutionResponse:
<<<<<<< HEAD
    prompt = SOLUTION_PROMPT.format(**req.model_dump())
    raw_output = generate(prompt)
    print("ðŸ§¾ Qwen ì‘ë‹µ ì›ë³¸:\n", raw_output)

    try:
        sections = raw_output.split("ë¬¸ì œ í•´ê²°:")
        problem_check = sections[0].replace("ë¬¸ì œ í™•ì¸:", "").strip()

        rest = sections[1].split("ì½”ë©˜íŠ¸:")
        problem_solving = rest[0].strip()

        comment_part = rest[1].split("ì •ë‹µ ì½”ë“œ:")
        comment = comment_part[0].strip()

        code_block = comment_part[1].strip()
        solution_code = code_block.strip("`").split("\n", 1)[-1].strip()

        return SolutionResponse(
            problem_check=problem_check,
            problem_solving=problem_solving,
            comment=comment,
            solution_code=solution_code,
        )

    except Exception as e:
        raise ValueError(f"Qwen ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}\nì¶œë ¥:\n{raw_output}")
=======
    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì— ë¬¸ì œ ì •ë³´ ì‚½ìž…
    prompt = SOLUTION_PROMPT.invoke(
        {
            "problem_number": req.problem_number,
            "title":          req.title,
            "description":    req.description,
            "input":          req.input,
            "output":         req.output,
            "input_example":  req.input_example,
            "output_example": req.output_example
        }
    )

    # LLMì— í”„ë¡¬í”„íŠ¸ ì „ì†¡í•˜ì—¬ í•´ì„¤ ìƒì„±
    result = await generate_solution(prompt)
    return result
>>>>>>> origin/dev
